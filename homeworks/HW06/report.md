# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: 12000 строк, 17 столбцов
- Целевая переменная: `target` (класс 0 - 67%, класс 1 - 32%)
- Признаки: числовые

## 2. Protocol

- Разбиение: train/test (80/20, `random_state` = 42)
- Подбор: CV на train (GridSearchCV, 5 фолдов, оптимизация по метрике `roc_auc`)
- Метрики: accuracy (базовая метрика), F1 (баланс точности/полноты, полезна, когда классы в данных несбалансированы), ROC-AUC (устойчивость модели к выбору порога, полезна, когда классы в данных несбалансированы)

## 3. Models

Базовые модели (без подбора параметров):
- DummyClassifier - делает прогнозы, игнорируя входные данные. Служит простой основой для сравнения с более сложными классификаторами
- LogisticRegression - прогнозирует  вероятность того, что входные данные относятся к определённому классу
Модели с подбором гиперпараметров:
- DecisionTreeClassifier - предсказывает значение целевой переменной путем обучения простым правилам принятия решений, выведенным из характеристик данных
Параметры: max_depth, min_samples_leaf и ccp_alpha
- RandomForestClassifier - строит множества независимых решающих деревьев и объединение их прогнозов для получения итогового результата
Параметры: n_estimators, max_depth и max_features
- GradientBoostingClassifier - последовательно создаёт набор слабых прогностических моделей, комбинируя их в единую сильную модель
Параметры: learning_rate, n_estimators и max_depth

## 4. Results

- Список финальных метрик на test по всем моделям:
"Dummy": "accuracy": 0.6766666666666666, "f1": 0.0, "roc_auc": 0.5
"LogisticRegression": "accuracy": 0.8275, "f1": 0.7076271186440678, "roc_auc": 0.8746905312071505
"DecisionTree": "accuracy": 0.8766666666666667, "f1": 0.8, "roc_auc": 0.9069205157178407
"RandomForest": "accuracy": 0.9270833333333334, "f1": 0.8816768086544963, "roc_auc": 0.9665023837032147 
"GradientBoosting": "accuracy": 0.9291666666666667, "f1": 0.8868175765645806, "roc_auc": 0.9689348877659846
- Победитель GradientBoostingClassifier. Показал лучший ROC-AUC (0.968), так как эффективно исправляет ошибки предыдущих деревьев

## 5. Analysis

- Устойчивость: При смене random_state метрики RandomForest стабильны (отклонение < 1.5%), DecisionTree более чувствительно к данным.
- Ошибки: Confusion matrix показывает, что модель иногда путает минорный класс с мажорным, но в целом ложноположительных срабатываний немного.
- Интерпретация: permutation importance позволили выделить три ключевых признака, имеющих наибольший вес в предсказаниях - num19, num18 и num07

## 6. Conclusion

- Деревья без контроля глубины мгновенно переобучаются (accuracy на трейне 1.0, на тесте низкая).
- Случайный лес значительно стабильнее одиночного дерева за счет усреднения.
- Бустинг дает лучший результат, но требует более тщательного подбора гиперпараметров.
- Честный протокол (отдельный тест) критически важен, так как CV на трейне иногда дает слишком оптимистичные оценки.
