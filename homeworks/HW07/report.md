# HW07 – Report

> Файл: `homeworks/HW07/report.md`  

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 8 столбцов
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: числовые признаки в разных шкалах, шумовые признаки

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 3 столбцов
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, выбросы, лишний шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 4 столбцов
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, фоновый шум

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: StandardScaler для масштабирования числовых признаков, PCA для визуализации результатов
- Поиск гиперпараметров:
  - для KMeans: диапазон k от 2 до 10; для DBSCAN: eps в диапазоне [0.1, 1.0] с шагом 0.1, min_samples в диапазоне [3, 5, 10]
  - при выборе "лучшего" основное внимение уделено основными метриками качества (silhouette score приоритетен), долей шума для DBSCAN, визуальной интерпретацией PCA-графиков, характером данных
- Метрики: silhouette_score (выше – лучше); davies_bouldin_score (ниже – лучше); calinski_harabasz_score (выше – лучше); для DBSCAN при наличии шума метрики считались только на non-noise точках
- Визуализация: PCA(2D) с раскраской по кластерам для лучшего решения каждого датасета; silhouette_score vs k для KMeans, графики подбора параметров

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для всех датасетов сравнивались два алгоритма:

KMeans:
- Поиск оптимального числа кластеров k в диапазоне 2-10
- Фиксированные параметры: random_state=42, n_init=10
- Критерий выбора k: максимальное значение silhouette_score
DBSCAN:
- Dataset A: подбор eps в диапазоне [0.1, 1.0], min_samples в диапазоне [3, 5, 10]
- Dataset B: подбор eps в диапазоне [0.1, 1.0], min_samples в диапазоне [3, 5, 10]
- Dataset C: подбор eps в диапазоне [0.1, 1.0], min_samples в диапазоне [3, 5, 10]
- Критерий выбора: максимальное значение silhouette_score на non-noise точках при разумной доле шума (<20%)



## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans (k=2)
- Метрики (silhouette / DB / CH): 0.52 / 0.68 / 11786
- Если был DBSCAN: доля шума: 0.0191 - данные содержат мало выбросов 
- Коротко: KMeans показал лучшие метрики качества, что 
соответствует сферической форме кластеров в данных. Масштабирование 
признаков было критически важно из-за различных шкал, что позволило
алгоритму корректно определить структуру

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN (eps=0.1, min_samples=10)
- Метрики (silhouette / DB / CH): 0.58 / 0.57 / 2758
- Если был DBSCAN: доля шума: 0.9185 - данные содержат много выбросов и данных с 
нелинейными формами
- Коротко: лишь небольшая часть точек образует плотные кластеры, 
а остальные — фон или выбросы. KMeans пытался принудительно распределить все точки 
по кластерам, что ухудшило качество


### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN (eps=0.1, min_samples=10)
- Метрики (silhouette / DB / CH): 0.81 / 0.24 / 3564
- Если был DBSCAN: доля шума: 0.995 - почти все точки отнесены к шуму, но 
оставшиеся образуют очень чёткие и компактные кластеры
- Коротко:  Несмотря на экстремально высокую долю шума, DBSCAN выявил небольшое число 
точек, формирующих кластеры исключительного качества. KMeans дал плохой результат, 
так как не смог адаптироваться к разной плотности и наличию фонового шума


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на данных с нелинейной структурой (Dataset B) и на данных 
с кластерами разной плотности (Dataset C). Алгоритм стремится создать сферические 
кластеры примерно одинакового размера, что противоречит реальной структуре 
этих данных
- DBSCAN выигрывает на датасетах с нелинейной структурой (B) и разной плотностью 
кластеров (C), эффективно выделяя шум и работая с произвольными формами кластеров. 
KMeans выигрывает на Dataset A благодаря сферической форме кластеров и отсутствию 
значительных выбросов
- Сильнее всего на результат влияло масштабирование признаков. На Dataset A без 
масштабирования качество кластеризации резко падало из-за различных шкал признаков. 
Выбросы и разная плотность (Datasets B и C) оказывали решающее влияние на выбор 
между KMeans и DBSCAN

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверку устойчивости проводили для Dataset B с использованием KMeans: 5 запусков с разными random_state (42, 43, 44, 45, 46)
- Получились следующие результаты: средний Adjusted Rand Index между 
запусками составил 0.9996 при стандартном отклонении 0.0004. 
Это указывает на высокую стабильность получаемых кластерных структур.
- Вывод: решение устойчиво, так как при разных начальных условиях алгоритм находит очень похожие разбиения. 
Высокое значение ARI и низкое стандартное отклонение подтверждает стабильность результатов.

### 5.3 Интерпретация кластеров

- Интерпретация кластеров проводилась через анализ значений признаков в центрах кластеров (для KMeans) и визуальный анализ распределений точек в кластерах (для DBSCAN)
- Для Dataset A: кластеры четко разделяются по значению первого признака (f01), что соответствует естественному разделению в данных
- Для Dataset B: кластеры имеют четкую нелинейную структуру, что подтверждает выбор DBSCAN как более подходящего метода
- Для Dataset C: выявлены кластеры разной плотности и размеров, что характерно для реальных данных с естественными группировками объектов. 
Шумовые точки равномерно распределены в пространстве признаков

## 6. Conclusion

- Выбор алгоритма кластеризации должен основываться на предполагаемой структуре данных: KMeans эффективен для сферических кластеров одинаковой плотности, DBSCAN лучше работает со сложными формами и разной плотностью
- Комплексная оценка качества кластеризации требует использования нескольких метрик, так как каждая из них имеет свои ограничения и чувствительна к разным аспектам структуры данных
- Визуализация (PCA) является важным инструментом для интерпретации и проверки результатов кластеризации, дополняющим численные метрики
- Проверка устойчивости результатов помогает оценить надежность полученных кластерных структур и избежать ложных выводов
- Учет шума и выбросов в данных требует специальных подходов, и алгоритмы, такие как DBSCAN, могут быть предпочтительнее в этих случаях
- Unsupervised-обучение требует особой осторожности в интерпретации результатов, так как отсутствие истинных меток затрудняет объективную оценку качества